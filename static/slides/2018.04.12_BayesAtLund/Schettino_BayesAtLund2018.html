<!DOCTYPE html>
<html>
  <head>
    <title>Analyzing an experiment on   involuntary attention using brms</title>
    <meta charset="utf-8">
    <meta name="author" content="Antonio Schettino    Department of Experimental-Clinical &amp; Health Psychology  Ghent University" />
    <link rel="stylesheet" href="Schettino_UGent_CSS.css" type="text/css" />
    <link rel="stylesheet" href="Schettino_UGent-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Analyzing an experiment on <br /> involuntary attention using <strong><code>brms</code></strong>
### Antonio Schettino<br /> <br /> Department of Experimental-Clinical &amp; Health Psychology<br /> Ghent University

---




layout: true

&lt;!-- set header --&gt;
&lt;div class="my-header"&gt;&lt;/div&gt;

&lt;!-- set footer --&gt;
&lt;div class="my-footer"&gt;&lt;span&gt;Antonio Schettino   
&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;
&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;
&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;
&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;
Bayes@Lund - 12.04.2018&lt;/span&gt;&lt;/div&gt;

&lt;!-- ################################### --&gt;
&lt;!-- ############# OUTLINE ############# --&gt;
&lt;!-- ################################### --&gt;

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- Good day everyone, my name is Antonio Schettino and I am a post-doctoral researcher at Ghent University.                       --&gt;
&lt;!-- Today I will show you the analyses (in progress) of some data collected during an experiment on involuntary spatial attention. --&gt;
&lt;!-- These analyses are conducted in R using the package brms by Paul Buerkner, one of the keynote speakers of this meeting.        --&gt;
&lt;!-- ############################################################################################################################## --&gt;

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- I will first give a broad background on what we are investigating.                                                             --&gt;
&lt;!-- Then I will show the experimental paradigm we used to address the issue.                                                       --&gt;
&lt;!-- I will then show you the data and mention what kind of analysis we performed.                                                  --&gt;
&lt;!-- Finally, I will give an overview of what we were able to learn with these analyses.                                            --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: outline

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.left[
  .font200[
    **OUTLINE**
  ]
]

&lt;br /&gt;

.font120[
  * background
]

.font120[
  * experimental paradigm
]

.font120[
  * data and results
]

.font120[
  * conclusions
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- Before starting, I would like to acknowledge the contribution of these people.                                                 --&gt;
&lt;!-- Sarina Evens collected the data of the pilot study and crafted a remarkable master thesis,                                     --&gt;
&lt;!-- which you can find on the Open Science Framework (https://osf.io/azh5r/).                                                      --&gt;
&lt;!-- Annelies Elegeert collected the data of the experiment I will present today.                                                   --&gt;
&lt;!-- Valentina Rossi and Gilles Pourtois are long-time collaborators                                                                --&gt;
&lt;!-- who helped with the experimental design and framing the theoretical background.                                                --&gt;
&lt;!-- ############################################################################################################################## --&gt;
--
&lt;!-- add collaborators picture --&gt;
&lt;Div style="margin-top:-380px" /&gt;

.right[
  ![collaborators](collaborators.jpg)
]

&lt;!-- ################################### --&gt;
&lt;!-- ############ BACKGROUND ########### --&gt;
&lt;!-- ################################### --&gt;

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- Let's start by clarifying what we wanted to study: involuntary attention.                                                      --&gt;
&lt;!-- Instead of giving a definition, perhaps a video might show this process more intuitively.                                      --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: notification_trolling

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Involuntary attention**
  ]
]

&lt;br /&gt;

&lt;!-- add video --&gt;
.center[
  &lt;body&gt;
  &lt;video width="320" height="240" controls="controls" vid.autoplay="false"&gt;
  &lt;source src="notification_troll.mp4" type="video/mp4"&gt;
  &lt;object data="" width="320" height="240"&gt;
  &lt;embed width="320" height="240" src="notification_troll.mp4"&gt;
  &lt;/object&gt;&lt;/video&gt;&lt;/body&gt;
  &lt;br /&gt;&lt;br /&gt;
  source: https://www.youtube.com/watch?v=0M2L9XNYfLs
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- So, what happened here?                                                                                                        --&gt;
&lt;!-- The guy in the background was attracted to the phone despite knowing that his friend was making the notification sounds.       --&gt;
&lt;!-- In other words, his attention was automatically attracted to his phone. Note that these sounds were not just uninformative     --&gt;
&lt;!-- (they were not signalling a real message), but were counterproductive,                                                         --&gt;
&lt;!-- because they distracted him from his current task (watching TV).                                                               --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: clarify_example1

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**What happened?**
  ]
]

--

.font120[
  * The guy in the background was attracted to the phone...
]

--

.font120[
  * ... despite *knowing* that his friend was making the notification sounds
]

--

.font120[
  * His attention was **automatically** attracted to ~~uninformative~~ **counterproductive** sounds (distraction from current task: watching TV)
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- This is just a funny example, but involuntary attention can also lead to dangerous consequences in real life.                  --&gt;
&lt;!-- For example, imagine driving your car in a busy road and suddenly being distracted by a flash on your mobile phone.            --&gt;
&lt;!-- You could cause an accident.                                                                                                   --&gt;
&lt;!-- Imagine a worker operating a hydraulic press and being distracted by a blinking light. They could get seriously injured.       --&gt;
&lt;!-- We need to understand this phenomenon deeply, but first we need to do it in controlled situations.                             --&gt;
&lt;!-- So how can we study it in the lab?                                                                                             --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: clarify_example2

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Why study involuntary attention?**
  ]
]

.font120[
  * Involuntary attentional orienting can be dangerous in some real-life situations
]

--

.font120[
  *  Car driver distracted by flashing mobile phone, worker operating heavy machinery distracted by blinking lights, ...
]

--

.font120[
  * How to study this phenomenon in the lab?
]

&lt;!-- ################################### --&gt;
&lt;!-- ###### EXPERIMENTAL PARADIGM ###### --&gt;
&lt;!-- ################################### --&gt;

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- One way would be to use a temporal order judgment task.                                                                        --&gt;
&lt;!-- In the simplest version of this experimental paradigm, two stimuli are briefly flashed on the screen and                       --&gt;
&lt;!-- observers have to say which stimulus appeared first.                                                                           --&gt;
&lt;!-- Difficulty varies as a function of Stimulus Onset Asynchrony (SOA), which is the time between the onset of the stimuli.        --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Temporal Order Judgment (TOJ)**
  ]
]

--

.font120[
  * Flash two stimuli on screen
]

--

.font120[
  * Task: which stimulus appeared **first**?
]

--

.font120[
  * Difficulty depends on the time between the onset of the stimuli (**SOA**)
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- This is an example of an easy trial.                                                                                           --&gt;
&lt;!-- Here the first stimulus (vertical lines) appear on the right side, followed by the second stimulus (horizontal lines).         --&gt;
&lt;!-- Participants have to judge which lines appear first.                                                                           --&gt;
&lt;!-- Changing the time between the onset of the two stimuli makes it easier or more difficult.                                      --&gt;
&lt;!-- Here timing is not correct due to technical limitations of the presentation, but at least you get my point.                    --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_example
background-image: url("TOJ_video.gif")
background-size: 700px
background-position: 50% 65%

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Temporal Order Judgment (TOJ)**
  ]
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- In our modified version of this paradigm, we use an exogenous cue to attract attention to one of the two placeholders.         --&gt;
&lt;!-- This creates the illusion of perceiving the stimulus at the attended location as appearing first even when it's not true.      --&gt;
&lt;!-- Now, what would happen if we present a cue that is always wrong, always appearing on the location of the second stimulus?      --&gt;
&lt;!-- Would participants' attention still automatically shift towards that location, even though it's counterproductive?             --&gt;
&lt;!-- This would be strong evidence that people cannot suppress this automatic urge to look at the cued location.                    --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_cue

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Counterproductive TOJ**
  ]
]

.font120[
  * An **exogenous cue** is used to attract attention towards one placeholder
]

--

.font120[
  * The stimulus on the attended location is perceived as **first** even when appearing second
]

--

.font120[
  * What if the cue is **always wrong**, i.e., appearing on the location of the *second* stimulus?
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- This is an example of this modified paradigm.                                                                                  --&gt;
&lt;!-- Here the cue (a thick placeholder box) appears on the left,                                                                    --&gt;
&lt;!-- then the first stimulus (horizontal lines) appear on the right side,                                                           --&gt;
&lt;!-- followed by the second stimulus (the vertical lines).                                                                          --&gt;
&lt;!-- So, the correct answer would be to judge the horizontal lines as appearing first but,                                          --&gt;
&lt;!-- because of the cue, participants should be more inclined to say that the vertical lines appeared first.                        --&gt;
&lt;!-- Again, timing here is not correct, this example is just to get the point across.                                               --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_video_cue
background-image: url("TOJ_video_cue.gif")
background-size: 700px
background-position: 50% 80%

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Counterproductive TOJ**
  ]
]

&lt;!-- ################################### --&gt;
&lt;!-- ########## DATA &amp; RESULTS ######### --&gt;
&lt;!-- ################################### --&gt;

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- This is a visualization of the data.                                                                                           --&gt;
&lt;!-- On the x-axis you see the SOAs. Positive SOAs mean that the horizontal lines were presented first,                             --&gt;
&lt;!-- negative SOAs mean that the vertical lines were presented first.                                                               --&gt;
&lt;!-- On the y-axis you see the proportion of times people judged the horizontal lines as appearing first.                           --&gt;
&lt;!-- X-axis: FACT. Y-axis: PERCEPTION.                                                                                              --&gt;
&lt;!-- The black line represents responses when no cue was presented, our baseline condition.                                         --&gt;
&lt;!-- When the vertical lines appear long before the horizontal lines,                                                               --&gt;
&lt;!-- people should almost never judge the horizontal lines as appearing first. This is what we see here.                            --&gt;
&lt;!-- The shorter the SOA, the more uncertain people are in their judgment. When the stimuli are presented simultaneously,           --&gt;
&lt;!-- there is a 50/50 chance of perceiving the horizontal or vertical lines as first.                                               --&gt;
&lt;!-- What happens when the horizontal lines are cued (blue line)?                                                                   --&gt;
&lt;!-- If the horizontal lines are cued, it means that the vertical lines always appeared first.                                      --&gt;
&lt;!-- However, participants say more often that the horizontal lines appeared first because they were cued.                          --&gt;
&lt;!-- The reverse effect can be seen when the vertical lines were cued.                                                              --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_graph

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**TOJ - Data**
  ]
]

&lt;Div style="margin-top:-40px" /&gt;

.center[
![](Schettino_BayesAtLund2018_files/figure-html/TOJ_plot-1.svg)&lt;!-- --&gt;
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- We analyzed these data using Bayesian multilevel modeling in brms.                                                             --&gt;
&lt;!-- Because the data were binary (a bunch of 2s and 8s), we fitted multilevel logistic regressions                                 --&gt;
&lt;!-- and allowed participants' intercepts and slopes to vary.                                                                       --&gt;
&lt;!-- On all the parameters of interest, we placed highly informative priors (posterior distributions obtained in a pilot study).    --&gt;
&lt;!-- We fitted several models and quantified which one had the best predictive validity.                                            --&gt;
&lt;!-- Once we identified the winning model, we ran diagnostics and posterior predictive checks and did some hypothesis testing.      --&gt;
&lt;!-- ############################################################################################################################## --&gt;

&lt;!-- Incremental lists do not give me what I want (due to increased font formatting and spacing), --&gt;
&lt;!-- so I created new slides and duplicated the content. Not elegant, but effective.              --&gt;
---
name: TOJ_analysis_desc1

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling**
  ]
]

---
name: TOJ_analysis_desc2

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling**
  ]
]

.font120[
* logistic regression, varying intercepts &amp; slopes on *participants*
]

---
name: TOJ_analysis_desc3

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling**
  ]
]

.font120[
* logistic regression, varying intercepts &amp; slopes on *participants*
* **highly informative priors** (from a pilot study)
]

---
name: TOJ_analysis_desc4

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling**
  ]
]

.font120[
* logistic regression, varying intercepts &amp; slopes on *participants*
* **highly informative priors** (from a pilot study)
* model comparison:
  1. full model (**SOA** + **cue** + **SOA** x **cue**)
  2. main effects (**SOA** + **cue**)
  3. main effect of **SOA**
  4. main effect of **cue**
  5. **null** model (intercept only)
]

---
name: TOJ_analysis_desc5

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling**
  ]
]

.font120[
* logistic regression, varying intercepts &amp; slopes on *participants*
* **highly informative priors** (from a pilot study)
* model comparison:
  1. full model (**SOA** + **cue** + **SOA** x **cue**)
  2. main effects (**SOA** + **cue**)
  3. main effect of **SOA**
  4. main effect of **cue**
  5. **null** model (intercept only)
* on the winning model:
  - diagnostics &amp; posterior predictive checks
  - hypothesis testing
]

&lt;!-- ###################################### --&gt;
&lt;!-- #### MODEL SPECIFICATION IN BRMS ##### --&gt;
&lt;!-- ###################################### --&gt;

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- This is the syntax in brms.                                                                                                    --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- First, you should specify the model formula. Here, the dependent variable is the number of trials                              --&gt;
&lt;!-- in which participants responded "horizontal first" over all trials.                                                            --&gt;
&lt;!-- "Conditions" is the name of the variable containing all condition combinations                                                 --&gt;
&lt;!-- (e.g., no cue at SOA-217, horizontal cued at SOA+83, ...). It is our population-level (or fixed) effect.                       --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- Then we specify the group-level (or random) effects.                                                                           --&gt;
&lt;!-- In this case, we allow intercepts and slopes to vary across participants for each condition combination.                       --&gt;
&lt;!-- What does it practically mean? For example:                                                                                    --&gt;
&lt;!-- - participant 1 could overall be slower than participant 2; or                                                                 --&gt;
&lt;!-- - participant 17 could be faster at SOA 217 but slower at SOA150 compared to participant 19;                                   --&gt;
&lt;!-- - ... you get the idea.                                                                                                        --&gt;
&lt;!-- Here, || is used to prevent group-level correlations from being modeled.                                                       --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- This is the name of the data frame containing your data.                                                                       --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- Here we specify the likelihood function.                                                                                       --&gt;
&lt;!-- The data are a bunch of 2s and 8s (the participant did/didn't respond "horizontal first"), hence the binomial distribution.    --&gt;
&lt;!-- The 'logit' link allows us to interpret the resulting coefficients in terms of odds ratios.                                    --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- Priors.full indicates a list with highly informative priors.                                                                   --&gt;
&lt;!-- We ran a pilot study identical to this one, fitted this same model (with default priors),                                      --&gt;
&lt;!-- and used the posterior distributions of those parameters as priors for this model.                                             --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- We tell brms to extract samples from the priors... they will be useful later on.                                               --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- These settings refer to the No-U-Turn-Sampler (NUTS) in STAN:                                                                  --&gt;
&lt;!-- - inits: initial parameter values in the Markov-Chain Monte Carlo (MCMC) chains;                                               --&gt;
&lt;!-- - control: steps of the NUTS sampler;                                                                                          --&gt;
&lt;!-- - chains: number of MCMC chains;                                                                                               --&gt;
&lt;!-- - iter: number of iterations for each MCMC chain;                                                                              --&gt;
&lt;!-- - warmup: number of burn-in samples (not included in final posterior distribution);                                            --&gt;
&lt;!-- - thin: thinning rate (to decrease autocorrelation);                                                                           --&gt;
&lt;!-- - algorithm: type of sampling algorithm;                                                                                       --&gt;
&lt;!-- - cores: numer of processor cores for parallel computations;                                                                   --&gt;
&lt;!-- - seed: seed for RNG (to ensure reproducible results).                                                                         --&gt;
&lt;!-- For details, see help(brm).                                                                                                    --&gt;
&lt;!-- ############################################################################################################################## --&gt;

&lt;!-- Incremental lists do not give me what I want (due to increased font formatting and spacing), --&gt;
&lt;!-- so I created new slides and duplicated the content. Not elegant, but effective.              --&gt;
---
name: TOJ_analysis_model

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling with ```brms```**
  ]
]

&lt;Div style="margin-top:-30px" /&gt;

```r
##################### full model (SOA * cue) #####################
model.full &lt;- brm(num.horiz1st | trials(tot.trials) ~ SOA * cue +
              (SOA * cue || participant), 
              data = data.TOJ,
              family = binomial("logit"),
              prior = priors.full,
              sample_prior = TRUE,
              inits = "random",
              control = list(adapt_delta = .9),
              chains = 4,
              iter = 2000,
              warmup = 500,
              thin = 1,
              algorithm = "sampling",
              cores = 4,
              seed = 9001)
```

---
name: TOJ_analysis_model_highlight1

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling with ```brms```**
  ]
]

&lt;Div style="margin-top:-30px" /&gt;

```r
##################### full model (SOA * cue) #####################
*   model.full &lt;- brm(num.horiz1st | trials(tot.trials) ~ SOA * cue +
              (SOA * cue || participant),
              data = data.TOJ,
              family = binomial("logit"),
              prior = priors.full,
              sample_prior = TRUE,
              inits = "random",
              control = list(adapt_delta = .9),
              chains = 4,
              iter = 2000,
              warmup = 500,
              thin = 1,
              algorithm = "sampling",
              cores = 4,
              seed = 9001)
```

---
name: TOJ_analysis_model_highlight2

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling with ```brms```**
  ]
]

&lt;Div style="margin-top:-30px" /&gt;

```r
##################### full model (SOA * cue) #####################
model.full &lt;- brm(num.horiz1st | trials(tot.trials) ~ SOA * cue +
*                (SOA * cue || participant),
              data = data.TOJ,
              family = binomial("logit"),
              prior = priors.full,
              sample_prior = TRUE,
              inits = "random",
              control = list(adapt_delta = .9),
              chains = 4,
              iter = 2000,
              warmup = 500,
              thin = 1,
              algorithm = "sampling",
              cores = 4,
              seed = 9001)
```

---
name: TOJ_analysis_model_highlight3

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling with ```brms```**
  ]
]

&lt;Div style="margin-top:-30px" /&gt;

```r
##################### full model (SOA * cue) #####################
model.full &lt;- brm(num.horiz1st | trials(tot.trials) ~ SOA * cue +
              (SOA * cue || participant),
*                data = data.TOJ,
              family = binomial("logit"),
              prior = priors.full,
              sample_prior = TRUE,
              inits = "random",
              control = list(adapt_delta = .9),
              chains = 4,
              iter = 2000,
              warmup = 500,
              thin = 1,
              algorithm = "sampling",
              cores = 4,
              seed = 9001)
```

---
name: TOJ_analysis_model_highlight4

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling with ```brms```**
  ]
]

&lt;Div style="margin-top:-30px" /&gt;

```r
##################### full model (SOA * cue) #####################
model.full &lt;- brm(num.horiz1st | trials(tot.trials) ~ SOA * cue +
              (SOA * cue || participant),
              data = data.TOJ,
*                family = binomial("logit"),
              prior = priors.full,
              sample_prior = TRUE,
              inits = "random",
              control = list(adapt_delta = .9),
              chains = 4,
              iter = 2000,
              warmup = 500,
              thin = 1,
              algorithm = "sampling",
              cores = 4,
              seed = 9001)
```

---
name: TOJ_analysis_model_highlight5

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling with ```brms```**
  ]
]

&lt;Div style="margin-top:-30px" /&gt;

```r
##################### full model (SOA * cue) #####################
model.full &lt;- brm(num.horiz1st | trials(tot.trials) ~ SOA * cue +
              (SOA * cue || participant),
              data = data.TOJ,
              family = binomial("logit"),
*                prior = priors.full,
              sample_prior = TRUE,
              inits = "random",
              control = list(adapt_delta = .9),
              chains = 4,
              iter = 2000,
              warmup = 500,
              thin = 1,
              algorithm = "sampling",
              cores = 4,
              seed = 9001)
```

---
name: TOJ_analysis_model_highlight6

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling with ```brms```**
  ]
]

&lt;Div style="margin-top:-30px" /&gt;

```r
##################### full model (SOA * cue) #####################
model.full &lt;- brm(num.horiz1st | trials(tot.trials) ~ SOA * cue +
              (SOA * cue || participant),
              data = data.TOJ,
              family = binomial("logit"),
              prior = priors.full,
*                sample_prior = TRUE,
              inits = "random",
              control = list(adapt_delta = .9),
              chains = 4,
              iter = 2000,
              warmup = 500,
              thin = 1,
              algorithm = "sampling",
              cores = 4,
              seed = 9001)
```

---
name: TOJ_analysis_model_highlight7

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling with ```brms```**
  ]
]

&lt;Div style="margin-top:-30px" /&gt;

```r
##################### full model (SOA * cue) #####################
model.full &lt;- brm(num.horiz1st | trials(tot.trials) ~ SOA * cue +
              (SOA * cue || participant),
              data = data.TOJ,
              family = binomial("logit"),
              prior = priors.full,
              sample_prior = TRUE,
*                inits = "random",
*                control = list(adapt_delta = .9),
*                chains = 4,
*                iter = 2000,
*                warmup = 500,
*                thin = 1,
*                algorithm = "sampling",
*                cores = 4,
*                seed = 9001)
```

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- To specify the other models, change the name of the independent variable                                                       --&gt;
&lt;!-- and set the priors of the appropriate model.                                                                                   --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_analysis_model_highlight8

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Bayesian multilevel modeling with ```brms```**
  ]
]

&lt;Div style="margin-top:-30px" /&gt;

```r
##################### main effect of SOA #####################
*   model.SOA &lt;- brm(num.horiz1st | trials(tot.trials) ~ SOA +
*                 (SOA || participant),
              data = data.TOJ,
              family = binomial("logit"),
*                 prior = priors.SOA,
              sample_prior = TRUE,
              inits = "random",
              control = list(adapt_delta = .9),
              chains = 4,
              iter = 2000,
              warmup = 500,
              thin = 1,
              algorithm = "sampling",
              cores = 4,
              seed = 9001)
```

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- We fitted all the models and compared their out-of-sample predictive validity through leave-one-out cross-validation.          --&gt;
&lt;!-- We iteratively fit each model on all observations except one, and then try to predict the one we left out.                     --&gt;
&lt;!-- The results indicated that the model with the lowest information loss was the one with both main effects, but no interaction.  --&gt;
&lt;!-- In other words, the effects of SOA and cue independently affect responses but do not interact with each other.                 --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_LOO

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Model comparison with ```brms```**
  ]
]

&lt;Div style="margin-top:-30px" /&gt;

.center[
  .font130[(*leave-one-out* cross-validation)
  ]
]

```r
model.comparison &lt;- LOO( # list with all models
                      model.full, model.mains, model.SOA, model.cue, model.null,
                      reloo = TRUE, # exact CV for problematic observations
                      compare = FALSE) # do not compare models with each other
```

.center[
  .font130[
  
  ```
  ##   models  LOO.IC
  ## 1  mains 2727.31
  ## 2   full 2844.49
  ## 3    SOA 3628.22
  ## 4    cue 7998.10
  ## 5   null 8275.49
  ```
  ]
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- This is the output that brms gives you.                                                                                        --&gt;
&lt;!-- For brevity, here I am only showing the output of the constant ("fixed") effects.                                              --&gt;
&lt;!-- You can see mean, estimated error, and 95% credible intervals                                                                  --&gt;
&lt;!-- of the posterior distributions of all the parameters of this model (the intercept is SOA0, no cue).                            --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- "Effective sample" is an estimate of the number of independent draws from the posterior distribution.                          --&gt;
&lt;!-- The closer this number is to the total number of samples (in this case, 6,000), the better the estimation.                     --&gt;
&lt;!-- As a rule of thumb, the ratio between the effective and total samples should not be lower than .1.                             --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- "Rhat" measures the ratio of the average variance of samples within each chain                                                 --&gt;
&lt;!-- to the variance of the pooled samples between chains. If all chains converge (i.e., they are at equilibrium), Rhat = 1.        --&gt;
&lt;!-- As a rule of thumb, Rhat should not be higher than 1.05.                                                                       --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_analysis_output

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**```brms``` output**
  ]
]

&lt;Div style="margin-top:-40px" /&gt;

.center[
  .font130[(**main effects** model, only **constant** effects)
  ]
]


```
##  [1] "Population-Level Effects: "                                             
##  [2] "                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat"
##  [3] "Intercept              0.06      0.06    -0.06     0.19       4716 1.00"
##  [4] "SOAM217               -2.64      0.13    -2.89    -2.38       4256 1.00"
##  [5] "SOAM150               -2.23      0.13    -2.50    -1.97       3727 1.00"
##  [6] "SOAM83                -1.53      0.10    -1.73    -1.34       4928 1.00"
##  [7] "SOAM17                -0.35      0.06    -0.47    -0.22       6000 1.00"
##  [8] "SOAP17                 0.21      0.06     0.09     0.33       6000 1.00"
##  [9] "SOAP83                 1.60      0.11     1.39     1.81       4528 1.00"
## [10] "SOAP150                2.42      0.16     2.11     2.72       3422 1.00"
## [11] "SOAP217                2.73      0.16     2.41     3.06       3851 1.00"
## [12] "cuevertical.cued      -0.80      0.06    -0.93    -0.68       6000 1.00"
## [13] "cuehorizontal.cued     0.86      0.07     0.73     1.00       5145 1.00"
```

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- You can visually explore the MCMC chains, to see whether they converged.                                                       --&gt;
&lt;!-- For these representative parameters, the chains converged nicely onto the same parameter space ("fat hairy caterpillar").      --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_analysis_MCMCchains

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**MCMC chains**
  ]
]

&lt;br /&gt;
&lt;Div style="margin-left:-50px" /&gt;

.pull-left[
  ```r
  library(bayesplot)
  mcmc_trace(as.array(model.mains),
  pars = c("b_Intercept", 
    "b_cuevertical.cued", 
    "b_cuehorizontal.cued"),
  facet_args = list(ncol=1))
  ```
]

&lt;Div style="margin-right:-40px" /&gt;
&lt;Div style="margin-top:-100px" /&gt; 

.pull-right[
![](Schettino_BayesAtLund2018_files/figure-html/model_mains_MCMC-1.svg)&lt;!-- --&gt;
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- One way of verifying whether your model can adequately predict unobserved data                                                 --&gt;
&lt;!-- is by running graphical posterior predictive checks.                                                                           --&gt;
&lt;!-- Here the blue line is the mean of the observed data                                                                            --&gt;
&lt;!-- and the yellow histograms represent the posterior distributions of these parameters.                                           --&gt;
&lt;!-- We can see that observed and estimated data are quite similar.                                                                 --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_analysis_PPC

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Posterior Predictive Checks**
  ]
]

&lt;br /&gt;
&lt;Div style="margin-left:-50px" /&gt;

.code100[
  .pull-left[
    ```r
    pp_check(model.mains, 
    nsamples = NULL, 
    type = "stat_grouped", 
    group = "cue")
    ```
  ]
]

&lt;Div style="margin-right:-40px" /&gt;
&lt;Div style="margin-top:-100px" /&gt; 

.pull-right[
![](Schettino_BayesAtLund2018_files/figure-html/model_mains_PPC-1.svg)&lt;!-- --&gt;
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- This is another way of showing that the model generates data very similar to the observed data.                                --&gt;
&lt;!-- This is the same graph that I showed you earlier, but I also added the data generated by the model (dotted lines).             --&gt;
&lt;!-- Observed and predicted data are almost undistinguishable, suggesting that the same process may have generated them.            --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_analysis_predicted_observed

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Observed vs. predicted data**
  ]
]

&lt;Div style="margin-top:-40px" /&gt;

.center[
![](Schettino_BayesAtLund2018_files/figure-html/model_mains_obs_pred-1.svg)&lt;!-- --&gt;
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- Now, suppose we are interested in testing whether responses in the no cue condition                                            --&gt;
&lt;!-- are different from the vertical cued condition. Through the 'hypothesis' function in brms we can test whether                  --&gt;
&lt;!-- the 95% credible interval of the difference between these two posterior probabilities includes 0.                              --&gt;
&lt;!-- As you can see here, the two distributions are clearly different (there is no overlap),                                        --&gt;
&lt;!-- so we can confidently conclude that "horizontal first" responses are much more likely in the no cue condition                  --&gt;
&lt;!-- compared to the vertical cued condition.                                                                                       --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_analysis_hyptest_nocue_vertcued

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Hypothesis testing**
  ]
]

&lt;Div style="margin-top:-40px" /&gt;

.center[
  .font130[(**no cue** vs. **vertical cued** conditions)
  ]
]



&lt;Div style="margin-left:-40px" /&gt;

.code100[
  .pull-left[
  ```r
  # posterior probability
  # under the hypothesis
  # (no.cue=vertical.cued)
  # against its alternative
  # (no.cue=/=vertical.cued)
  hypothesis(model.mains, 
  "Intercept = Intercept + cuevertical.cued")
  ```
  ]
]

&lt;br /&gt;
&lt;Div style="margin-right:-40px" /&gt;
&lt;Div style="margin-top:-100px" /&gt; 

.pull-right[
![](Schettino_BayesAtLund2018_files/figure-html/model_mains_hyptest_nocue_vertcued_graph-1.svg)&lt;!-- --&gt;
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- In the same way, we can test whether the results of this experiment are different from the results of the pilot experiment     --&gt;
&lt;!-- by simply comparing the prior and posterior distributions of our parameters of interest.                                       --&gt;
&lt;!-- In this case, we can see a great overlap, indicating no difference between pilot and current experiment.                       --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: TOJ_analysis_hyptest_nocue_prior_posterior

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Hypothesis testing**
  ]
]

&lt;Div style="margin-top:-40px" /&gt;

.center[
  .font130[(**pilot** vs. **current** experiment)
  ]
]

![](Schettino_BayesAtLund2018_files/figure-html/model_mains_hyptest_prior_vs_post_graph-1.svg)&lt;!-- --&gt;

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- So, what have learned?                                                                                                         --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- We now know that SOA and cue affect performance independently.                                                                 --&gt;
&lt;!-- We reached this conclusion by comparing the predictive validity of all theoretically plausible models                          --&gt;
&lt;!-- via leave-one-out cross-validation procedures.                                                                                 --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- We have visually checked that the winning model can predict unobserved data pretty well.                                       --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- In line with our predictions, we have verified that "horizontal first" responses are less likely                               --&gt;
&lt;!-- when the vertical lines are cued compared to when no cue is presented.                                                         --&gt;
&lt;!-- This was possible by comparing the posterior distributions of these two parameters                                             --&gt;
&lt;!-- and show that their 95% credible intervals do not overlap.                                                                     --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- In the same way, we were also able to show (by comparing prior and posterior distributions) that                               --&gt;
&lt;!-- "horizontal first" response during the pilot and current experiment are virtually identical.                                   --&gt;
&lt;!--                                                                                                                                --&gt;
&lt;!-- There is so much more that can be done in brms... thank you Paul!                                                              --&gt;
&lt;!-- ############################################################################################################################## --&gt;
---
name: conclusions1

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Conclusions**
  ]
]

.font110[
  What we have learned:
]

---
name: conclusions2

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Conclusions**
  ]
]

.font110[
  What we have learned:
  * SOA and cue influence performance **independently**
    - comparison of *theoretically plausible* multilevel models
]

---
name: conclusions3

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Conclusions**
  ]
]

.font110[
  What we have learned:
  * SOA and cue influence performance **independently**
    - comparison of *theoretically plausible* multilevel models
  * the winning model is the best in terms of **predictive accuracy**
]

---
name: conclusions4

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Conclusions**
  ]
]

.font110[
  What we have learned:
  * SOA and cue influence performance **independently**
    - comparison of *theoretically plausible* multilevel models
  * the winning model is the best in terms of **predictive accuracy**
  * **observed** and **predicted** data are very similar
]

---
name: conclusions5

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Conclusions**
  ]
]

.font110[
  What we have learned:
  * SOA and cue influence performance **independently**
    - comparison of *theoretically plausible* multilevel models
  * the winning model is the best in terms of **predictive accuracy**
  * **observed** and **predicted** data are very similar
  * *"horizontal first"* responses are less likely when the *vertical* lines are cued
    - comparison of the posterior distributions of no cue and vertical cued conditions
]

---
name: conclusions6

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Conclusions**
  ]
]

.font110[
  What we have learned:
  * SOA and cue influence performance **independently**
    - comparison of *theoretically plausible* multilevel models
  * the winning model is the best in terms of **predictive accuracy**
  * **observed** and **predicted** data are very similar
  * *"horizontal first"* responses are less likely when the *vertical* lines are cued
    - comparison of the posterior distributions of no cue and vertical cued conditions
  * data of **pilot** and **current** experiment are very similar
    - comparison of prior and posterior distributions of cue conditions
]

---
name: conclusions7

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font200[**Conclusions**
  ]
]

.font110[
  What we have learned:
  * SOA and cue influence performance **independently**
    - comparison of *theoretically plausible* multilevel models
  * the winning model is the best in terms of **predictive accuracy**
  * **observed** and **predicted** data are very similar
  * *"horizontal first"* responses are less likely when the *vertical* lines are cued
    - comparison of the posterior distributions of no cue and vertical cued conditions
  * data of **pilot** and **current** experiment are very similar
    - comparison of prior and posterior distributions of cue conditions
  * ... and much more! Thanks for ```brms```, @paulbuerkner!
]

&lt;!-- ##################################################### NOTES ################################################################## --&gt;
&lt;!-- I would also like to thank you for your attention. 
&lt;!-- If you want to keep in touch, this is my email, website, and Twitter handle.
&lt;!-- You can also find these slides on this blog post on my website.
&lt;!-- ############################################################################################################################## --&gt;
---
name: thanks

&lt;!-- set FontAwesome icons --&gt;
&lt;link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"&gt;

&lt;Div style="margin-top:90px" /&gt; &lt;!-- start below university header --&gt;

.center[
  .font300[**Thanks for your attention!**]
]

&lt;br /&gt;

.center[
  .font150[
    &lt;a href="mailto:antonio.schettino@ugent.be"&gt; &lt;i class="fa fa-paper-plane fa-fw" style="font-size:30px;color:#152bda;"&gt; &lt;/i&gt;&amp;nbsp; antonio.schettino@ugent.be&lt;/a&gt;&lt;br&gt;
    &lt;a href="https://asch3tti.netlify.com/"&gt;&lt;i class="fa fa-link fa-fw" style="font-size:30px;color:black;"&gt;&lt;/i&gt;&amp;nbsp; asch3tti.netlify.com&lt;/a&gt;&lt;br&gt;
    &lt;a href="https://twitter.com/asch3tti"&gt;&lt;i class="fa fa-twitter fa-fw" style="font-size:35px;color:#00aced;"&gt;&lt;/i&gt;&amp;nbsp; @asch3tti&lt;/a&gt;&lt;br&gt;
&lt;br /&gt;
Slides available here: 
&lt;br /&gt;
https://asch3tti.netlify.com/post/bayesatlund2018/
  ]
]

&lt;!-- ################################### --&gt;
&lt;!-- ############## END ################ --&gt;
&lt;!-- ################################### --&gt;
    </textarea>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"self_contained": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
